{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593409bb-46b2-4a1d-acc5-8e60fe0774b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079ec22b-3f9b-4f49-bcb7-073b875ec350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7275a57-7868-4c92-a9be-154caf6d92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data.astype('float32'), mnist.target.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8953ad8b-bf68-4e2b-9993-ee82af5bcac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X /= 255.0  # Normalize pixel values to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e018af2-253d-4d81-a5bc-f256c7ccff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33b08e9-e3bd-43ff-be6c-5b45138c3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83b2741-2140-42c7-a5dc-dcaf6740549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "num_classes = 10\n",
    "y_train_encoded = np.eye(num_classes)[y_train]\n",
    "y_test_encoded = np.eye(num_classes)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7734e-2056-4c9d-bd65-2373927005e1",
   "metadata": {},
   "source": [
    "##  Define neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8221e9a5-e463-47e0-8432-14e2f89f5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weights1 = np.random.randn(self.input_dim, self.hidden_dim) * np.sqrt(2 / self.input_dim)\n",
    "        self.biases1 = np.zeros((1, self.hidden_dim))\n",
    "        self.weights2 = np.random.randn(self.hidden_dim, self.output_dim) * np.sqrt(2 / self.hidden_dim)\n",
    "        self.biases2 = np.zeros((1, self.output_dim))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_scores = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.hidden_output = 1 / (1 + np.exp(-np.dot(X, self.weights1) - self.biases1))\n",
    "        self.output = self.softmax(np.dot(self.hidden_output, self.weights2) + self.biases2)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        output_error = self.output - y\n",
    "        hidden_error = np.dot(output_error, self.weights2.T) * self.hidden_output * (1 - self.hidden_output)\n",
    "        \n",
    "        self.weights2 -= learning_rate * np.dot(self.hidden_output.T, output_error)\n",
    "        self.biases2 -= learning_rate * np.sum(output_error, axis=0, keepdims=True)\n",
    "        self.weights1 -= learning_rate * np.dot(X.T, hidden_error)\n",
    "        self.biases1 -= learning_rate * np.sum(hidden_error, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, y, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = -np.sum(y * np.log(output + 1e-9)) / len(y)  # Add a small epsilon to prevent log(0)\n",
    "            print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        hidden_output = 1 / (1 + np.exp(-np.dot(X, self.weights1) - self.biases1))\n",
    "        output = self.softmax(np.dot(hidden_output, self.weights2) + self.biases2)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c1f8a9-c314-47b2-8c25-b00a9670e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = num_classes\n",
    "learning_rate = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9880a1cc-ca17-4945-9814-b455a62d6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c02e7b20-fd85-4eba-93c3-4332c0b48d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 2.8910003653009837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhayanithi\\AppData\\Local\\Temp\\ipykernel_21976\\2053880583.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  self.hidden_output = 1 / (1 + np.exp(-np.dot(X, self.weights1) - self.biases1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 18.680434879638465\n",
      "Epoch 2: Loss = 15.777346481144846\n",
      "Epoch 3: Loss = 15.869617988771834\n",
      "Epoch 4: Loss = 17.005589295165503\n",
      "Epoch 5: Loss = 14.982141618326969\n",
      "Epoch 6: Loss = 15.542154428274532\n",
      "Epoch 7: Loss = 15.612583024131398\n",
      "Epoch 8: Loss = 16.43101308886039\n",
      "Epoch 9: Loss = 15.74167301374361\n",
      "Epoch 10: Loss = 18.01362594784198\n",
      "Epoch 11: Loss = 13.716101737448842\n",
      "Epoch 12: Loss = 13.558423882333136\n",
      "Epoch 13: Loss = 11.278413032530462\n",
      "Epoch 14: Loss = 9.89346726070972\n",
      "Epoch 15: Loss = 9.542324214275636\n",
      "Epoch 16: Loss = 8.881774719561054\n",
      "Epoch 17: Loss = 8.251278544388205\n",
      "Epoch 18: Loss = 8.353943923591942\n",
      "Epoch 19: Loss = 8.656238557262812\n",
      "Epoch 20: Loss = 7.1911989586874325\n",
      "Epoch 21: Loss = 6.396445172036595\n",
      "Epoch 22: Loss = 5.933124658207709\n",
      "Epoch 23: Loss = 5.842021635187154\n",
      "Epoch 24: Loss = 5.808119122993977\n",
      "Epoch 25: Loss = 5.880893193556762\n",
      "Epoch 26: Loss = 5.631371150136208\n",
      "Epoch 27: Loss = 5.843811644596619\n",
      "Epoch 28: Loss = 5.094941057444593\n",
      "Epoch 29: Loss = 5.210555901654126\n",
      "Epoch 30: Loss = 4.309856076383317\n",
      "Epoch 31: Loss = 4.305529583468444\n",
      "Epoch 32: Loss = 4.069405412286159\n",
      "Epoch 33: Loss = 4.020998974101859\n",
      "Epoch 34: Loss = 4.013942410905369\n",
      "Epoch 35: Loss = 4.092913552684168\n",
      "Epoch 36: Loss = 3.9755295998187714\n",
      "Epoch 37: Loss = 3.986207535374074\n",
      "Epoch 38: Loss = 3.8461594897227287\n",
      "Epoch 39: Loss = 3.9248883718660474\n",
      "Epoch 40: Loss = 3.8837518996840696\n",
      "Epoch 41: Loss = 4.0297442887940775\n",
      "Epoch 42: Loss = 3.8455850115837515\n",
      "Epoch 43: Loss = 3.9548515815509324\n",
      "Epoch 44: Loss = 4.001339030296978\n",
      "Epoch 45: Loss = 4.096113234947118\n",
      "Epoch 46: Loss = 4.371588535748769\n",
      "Epoch 47: Loss = 4.406744750147111\n",
      "Epoch 48: Loss = 4.785803940407835\n",
      "Epoch 49: Loss = 4.617935092835616\n",
      "Epoch 50: Loss = 4.752258575097966\n",
      "Epoch 51: Loss = 4.7943005991154175\n",
      "Epoch 52: Loss = 4.6441862016186795\n",
      "Epoch 53: Loss = 5.132074074366648\n",
      "Epoch 54: Loss = 6.037925520424784\n",
      "Epoch 55: Loss = 5.702867964824945\n",
      "Epoch 56: Loss = 5.04775672983066\n",
      "Epoch 57: Loss = 4.816248183706635\n",
      "Epoch 58: Loss = 3.5649867038888425\n",
      "Epoch 59: Loss = 3.357692337771879\n",
      "Epoch 60: Loss = 3.1603285980303872\n",
      "Epoch 61: Loss = 3.1553633133713253\n",
      "Epoch 62: Loss = 3.082348276880253\n",
      "Epoch 63: Loss = 3.1600372788243605\n",
      "Epoch 64: Loss = 3.10243239498685\n",
      "Epoch 65: Loss = 3.1422003374369205\n",
      "Epoch 66: Loss = 3.3435565381346604\n",
      "Epoch 67: Loss = 3.6358121797554794\n",
      "Epoch 68: Loss = 3.8993234383391453\n",
      "Epoch 69: Loss = 4.156523858912631\n",
      "Epoch 70: Loss = 4.014024388861767\n",
      "Epoch 71: Loss = 4.057866196744832\n",
      "Epoch 72: Loss = 4.723697935132848\n",
      "Epoch 73: Loss = 5.913143762424199\n",
      "Epoch 74: Loss = 5.506750125970918\n",
      "Epoch 75: Loss = 4.572139555322276\n",
      "Epoch 76: Loss = 4.051357596194806\n",
      "Epoch 77: Loss = 3.407078774252873\n",
      "Epoch 78: Loss = 3.298825863825348\n",
      "Epoch 79: Loss = 3.362523006694164\n",
      "Epoch 80: Loss = 3.4321959622412472\n",
      "Epoch 81: Loss = 3.3114333919373924\n",
      "Epoch 82: Loss = 3.3387809421608057\n",
      "Epoch 83: Loss = 3.2389521274310455\n",
      "Epoch 84: Loss = 3.242031621615119\n",
      "Epoch 85: Loss = 3.1736783299568536\n",
      "Epoch 86: Loss = 3.203498070615332\n",
      "Epoch 87: Loss = 3.1015756713189835\n",
      "Epoch 88: Loss = 3.1180841462876607\n",
      "Epoch 89: Loss = 3.1171471930531993\n",
      "Epoch 90: Loss = 3.147299809115125\n",
      "Epoch 91: Loss = 3.0922267417853813\n",
      "Epoch 92: Loss = 3.11991992352075\n",
      "Epoch 93: Loss = 3.0767905176090196\n",
      "Epoch 94: Loss = 3.09243428835013\n",
      "Epoch 95: Loss = 3.0840382852550654\n",
      "Epoch 96: Loss = 3.078323556325378\n",
      "Epoch 97: Loss = 3.059028894480913\n",
      "Epoch 98: Loss = 3.116060406753422\n",
      "Epoch 99: Loss = 3.155991614853882\n"
     ]
    }
   ],
   "source": [
    "nn.train(X_train, y_train_encoded, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65796cef-83b0-4835-8813-c5a2b451b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhayanithi\\AppData\\Local\\Temp\\ipykernel_21976\\2053880583.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  hidden_output = 1 / (1 + np.exp(-np.dot(X, self.weights1) - self.biases1))\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4d36a3-e235-4cdf-9e15-95e57d5c09c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8383571428571429\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf32cb7-b3a6-48a3-88a7-8fe8bce505ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ba745-33c2-4586-a3ea-ef6c4b8c8a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e100ec-97f3-42fc-a5b0-3524f83e4cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b60924-716d-4afe-97f5-8e6dc23f0acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6f885-f80b-4bc1-be96-10577a23c497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7542cc0d-aeb7-4104-85e1-f016eff22819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f13c6a-27fd-4c04-9040-7ed4d57aa7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590242ab-a3e6-47d9-b7fe-a0381b6d89ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df182561-0bb7-409e-bf30-bb2b0793c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d9464-25c0-4f5a-96ba-7187778197b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c142249-0734-47ca-8662-1ba4fcf35cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b7274-8647-4b26-9b53-4ced2e04541e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d109e0-8d1e-44b9-a1a6-8d6d0ecd7d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
